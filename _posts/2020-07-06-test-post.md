---
layout: post
title: "Stock Prediction with Deep Q Learning"
date: 2020-07-06
---
## Problem Setup
---

Our goal is to create a model which will recommend what action to take today given the previous n days of data as input. More specifically, the input will be an n-length array of normalized daily adjusted close prices for a single stock. For this basic model we will have three possible actions:
1. Sell all held stocks
2. Buy with all available cash
3. Do nothing

We will train a neural network from scratch using TensorFlow and the reinforcement learning technique known as Q learning.

## Q Learning
---

Q learning is simply a mapping of a state, action pair (s, a) to a scalar value known as the q value. This value is indicative of the expected long term reward. Given a state s, the action a which has the largest expected cumulative reward will have the largest q value. Thus, if we are able to map all state, action pairs to a q value we can act optimally by simply selecting the action with the largest q value for the given state we are in.

### Learning the Mappings

To learn the mappings we explore the "world" as follows. (Note that we first initialize q values for each s, a pair typically to random small values or zeros)

1. Begin in some state, s (in our case we would start at some day, and the state would be the stock prices of the previous n days)
2. Take an action, a. This is often done using an e-greedy policy. In this policy we take a random action with probability e, and we take the assumed optimal action with probability 1 - e
3. Based on the action taken, move into the next state, s'
4. Get a reward, r, based on the transition from s to s'
5. Obtain the highest possible q value, q', for this new state s'. That is, scan the q values over all possible actions given s', and select the highest q value
6. Set the Q(s, a) mapping = r + gamma * q' where gamma is a reward discount factor



